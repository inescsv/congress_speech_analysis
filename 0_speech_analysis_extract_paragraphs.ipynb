{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congressional Speech Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "pd.options.display.max_columns = 1200  \n",
    "pd.options.display.max_rows = 1200 \n",
    "\n",
    "import unicodedata\n",
    "import itertools\n",
    "import datetime\n",
    "import datefinder\n",
    "import operator\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to generate the data frame of all 114th Congress hearings. The files are contained in directories following this structure:\n",
    "\n",
    "Data ---> Congress ---> Office ---> Department ---> Text files in txt format.\n",
    "\n",
    "Each text file is imported into the documents column of the data frame and assigned a document ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Congressional Hearings DF shape: (2535, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document</th>\n",
       "      <th>congress</th>\n",
       "      <th>office</th>\n",
       "      <th>department</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>1837</td>\n",
       "      <td>\\n - eastern mediterranean energy: challenges ...</td>\n",
       "      <td>114th</td>\n",
       "      <td>House</td>\n",
       "      <td>Ad Hoc Committee on Energy</td>\n",
       "      <td>1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1659</td>\n",
       "      <td>\\n - [errata] manipulation and fraud in the re...</td>\n",
       "      <td>114th</td>\n",
       "      <td>House</td>\n",
       "      <td>Commission on Security and Cooperation in Europe</td>\n",
       "      <td>1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1658</td>\n",
       "      <td>\\n - the rule of law and civil society in azer...</td>\n",
       "      <td>114th</td>\n",
       "      <td>House</td>\n",
       "      <td>Commission on Security and Cooperation in Europe</td>\n",
       "      <td>2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1657</td>\n",
       "      <td>\\n - human rights violations in russian-occupi...</td>\n",
       "      <td>114th</td>\n",
       "      <td>House</td>\n",
       "      <td>Commission on Security and Cooperation in Europe</td>\n",
       "      <td>3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1656</td>\n",
       "      <td>\\n - nato's warsaw summit and the future of eu...</td>\n",
       "      <td>114th</td>\n",
       "      <td>House</td>\n",
       "      <td>Commission on Security and Cooperation in Europe</td>\n",
       "      <td>4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      document_id                                           document congress  \\\n",
       "1837         1837  \\n - eastern mediterranean energy: challenges ...    114th   \n",
       "1659         1659  \\n - [errata] manipulation and fraud in the re...    114th   \n",
       "1658         1658  \\n - the rule of law and civil society in azer...    114th   \n",
       "1657         1657  \\n - human rights violations in russian-occupi...    114th   \n",
       "1656         1656  \\n - nato's warsaw summit and the future of eu...    114th   \n",
       "\n",
       "     office                                        department   name  \n",
       "1837  House                        Ad Hoc Committee on Energy  1.txt  \n",
       "1659  House  Commission on Security and Cooperation in Europe  1.txt  \n",
       "1658  House  Commission on Security and Cooperation in Europe  2.txt  \n",
       "1657  House  Commission on Security and Cooperation in Europe  3.txt  \n",
       "1656  House  Commission on Security and Cooperation in Europe  4.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "FILES_PATH = '/Users/yc00027/Documents/GitHub/congress_speech_analysis/Data'\n",
    "\n",
    "congresses = sorted(listdir_nohidden(FILES_PATH))\n",
    "\n",
    "congressional_hearings = []\n",
    "\n",
    "for congress in congresses:\n",
    "    clear_output()\n",
    "    print(f'Now loading congress {congress}')\n",
    "    offices = listdir_nohidden(congress)\n",
    "    for office in offices:\n",
    "        clear_output()\n",
    "        print(f'Now loading office {office}')\n",
    "        congress = os.path.split(os.path.dirname(office))[1]\n",
    "        departments = listdir_nohidden(office)\n",
    "        for department in departments:\n",
    "            clear_output()\n",
    "            office = os.path.split(os.path.dirname(department))[1]\n",
    "            try:\n",
    "                session_files = listdir_nohidden(department)\n",
    "            except:\n",
    "                print(f'No txt files for session {session}')\n",
    "                continue\n",
    "\n",
    "            txt_files = [f for f in session_files if f.endswith('.txt')]\n",
    "            for file in txt_files:\n",
    "                with open(file, errors='replace') as f:\n",
    "                    document = f.read().lower() \n",
    "                    department = os.path.split(os.path.dirname(file))[1]\n",
    "                    name = os.path.basename(file)\n",
    "                    congressional_hearings.append([document, congress, office, department, name])\n",
    "            \n",
    "clear_output()\n",
    "print('Done')\n",
    "\n",
    "congressional_hearings_df = pd.DataFrame(congressional_hearings).reset_index().rename(columns={'index': 'document_id'})\n",
    "congressional_hearings_df.columns = ['document_id', 'document', 'congress','office','department','name']\n",
    "congressional_hearings_df = congressional_hearings_df.sort_values(by=['congress', 'office','department','name'])\n",
    "\n",
    "print(f'Congressional Hearings DF shape: {congressional_hearings_df.shape}')\n",
    "congressional_hearings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data frame of bills for the 114th congress and extract full list of speaker names, number of bills and bill types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 12043 bills in Congress 114th.\n",
      "There were 542 speakers in Congress 114th.\n",
      "\n",
      "Number of bills according to bill type:\n",
      "hr         6508\n",
      "s          3547\n",
      "hres        956\n",
      "sres        642\n",
      "hconres     183\n",
      "hjres       108\n",
      "sconres      58\n",
      "sjres        41\n",
      "Name: BillType, dtype: int64\n",
      "\n",
      "Bill types: \"hr\" (House Bill); \"s\" (Senate Bill); \"hres\" (House Resolution); \"sres\" (Senate Resolution);                    \"hcon\" (House Concurrent Resolution); \"scon\" (Senate Concurrent Resolution);                    \"hjres\" (House Joint Resolution); \"sjres\" (Senate Joint Resolution).\n"
     ]
    }
   ],
   "source": [
    "bills93_114_df = pd.read_csv('bills93-114.csv', error_bad_lines=False, encoding='ISO-8859-1', sep = ';')\n",
    "bills_114 = bills93_114_df[bills93_114_df['Cong'] == 114]\n",
    "\n",
    "print(f'There were {bills_114.shape[0]} bills in Congress 114th.')\n",
    "\n",
    "speaker_names = sorted(bills_114['NameFull'].str.lower().unique())\n",
    "print(f'There were {len(speaker_names)} speakers in Congress 114th.')\n",
    "print('')\n",
    "\n",
    "print('Number of bills according to bill type:')\n",
    "print(bills_114['BillType'].value_counts())\n",
    "print('')\n",
    "\n",
    "print('Bill types: \"hr\" (House Bill); \"s\" (Senate Bill); \"hres\" (House Resolution); \"sres\" (Senate Resolution); \\\n",
    "                   \"hcon\" (House Concurrent Resolution); \"scon\" (Senate Concurrent Resolution); \\\n",
    "                   \"hjres\" (House Joint Resolution); \"sjres\" (Senate Joint Resolution).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data frame of chairmen for the 114th congress and extract full list of chairmen names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 165 chairmen of Committees and Subcommittees in Congress 114th.\n"
     ]
    }
   ],
   "source": [
    "chairmen_114 = pd.read_excel('chairmen.xlsx', 'all')\n",
    "chairmen_114 = chairmen_114[chairmen_114['Congress'] == 114]\n",
    "chairmen_114 = chairmen_114[(chairmen_114['Chair Committee'].astype(int) == 1) | (chairmen_114['Chair Subcommittee'].astype(int) == 1)] # | (chairmen_114['Vice Chair Committee'].astype(int) == 1) | (chairmen_114['Vice Chair subcommittee'].astype(int) == 1)]\n",
    "\n",
    "chairmen_names = sorted(chairmen_114['Name'].str.lower().unique())\n",
    "print(f'There were {len(chairmen_names)} chairmen of Committees and Subcommittees in Congress 114th.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the data frame of sentences for each document with respective sentence ID and speaker name. Match speaker names extracted from the hearings documents with the complete list of speakers extracted from the bills data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_points = []\n",
    "sentences = []\n",
    "keywords = ['senator', 'secretary', 'chairman', 'mr.', 'ms.', 'mrs.', 'doc.']\n",
    "\n",
    "for i, (document_id, document) in enumerate(zip(congressional_hearings_df['document_id'], congressional_hearings_df['document'])):\n",
    "    sent_text = sent_tokenize(document)\n",
    "        \n",
    "    for sentence_id, sentence in enumerate(sent_text):\n",
    "        sentences.append({\n",
    "            'document_id': document_id,\n",
    "            'sentence_id': sentence_id,\n",
    "            'sentence': sentence,\n",
    "        })\n",
    "\n",
    "        sentence_split = sentence.split(' ')\n",
    "        sentence_length = len(sentence_split) \n",
    "        if sentence_length < 2:\n",
    "            continue\n",
    "        first_word = sentence_split[0]\n",
    "        sentence_is_start_sentence = sentence_length == 2 and first_word in keywords\n",
    "        sentence_is_start_statement = 'statement of'in sentence\n",
    "        if sentence_is_start_sentence:\n",
    "            speaker_name = sentence_split[1].strip('.?')\n",
    "            starting_points.append({\n",
    "                'document_id': document_id,\n",
    "                'speaker_name': speaker_name,\n",
    "                'speech_id': sentence_id,\n",
    "            })\n",
    "        elif sentence_is_start_statement:\n",
    "            try: \n",
    "                speaker_name = sent_text[sentence_id+1].split(', ')[0]\n",
    "                starting_points.append({\n",
    "                    'document_id': document_id,\n",
    "                    'speaker_name': speaker_name,\n",
    "                    'speech_id': sentence_id,\n",
    "                })\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "starting_points = pd.DataFrame(starting_points)\n",
    "sentences = pd.DataFrame(sentences)\n",
    "\n",
    "sentences_df = pd.merge(sentences, starting_points, left_on=['document_id', 'sentence_id'], \\\n",
    "                     right_on=['document_id', 'speech_id'], how='left')\n",
    "\n",
    "sentences_df = sentences_df.groupby('document_id').ffill()\n",
    "sentences_df = sentences_df.fillna(0)\n",
    "\n",
    "f = lambda x: next(iter(name for name in speaker_names if str(x) in name), 'no match')\n",
    "sentences_df['clean_speaker_name'] = sentences_df['speaker_name'].apply(f)\n",
    "\n",
    "sentences_df.drop(columns=['speaker_name'], inplace=True)\n",
    "\n",
    "print(f'Sentences DF shape: {sentences_df.shape}')\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group sentences into speeches and extract title, date and chairman name from first block of each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df = sentences_df.groupby(['document_id', 'speech_id'])['sentence'].apply(lambda x: ','.join(x)).reset_index()\n",
    "blocks_df.columns = ['document_id', 'speech_id', 'speech']\n",
    "\n",
    "document_title = []\n",
    "hearing_date = []\n",
    "\n",
    "for i, (speech_id, speech) in enumerate(zip(blocks_df['speech_id'], blocks_df['speech'])):\n",
    "    if speech_id == 0:\n",
    "        title = speech.split('\\n')[1].replace(' - ', '')\n",
    "        regex_date = re.compile(r'(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{1,2},\\s+\\d{4}')\n",
    "        date = regex_date.findall(speech)\n",
    "        document_title.append(title)\n",
    "        hearing_date.append(date)\n",
    "    else:\n",
    "        document_title.append(np.nan)\n",
    "        hearing_date.append(np.nan)\n",
    "\n",
    "chairmen = []\n",
    "\n",
    "for index, (speech_id, speech) in enumerate(zip(blocks_df['speech_id'], blocks_df['speech'])):\n",
    "    if speech_id != 0:\n",
    "        chairmen.append(np.nan)\n",
    "    elif speech_id == 0:\n",
    "        split_speech = speech.splitlines()\n",
    "        chairman_names = []\n",
    "        for i, line in enumerate(split_speech):\n",
    "            try:\n",
    "                line_plus_2_long = split_speech[i+2] + split_speech[i+3] + split_speech[i+4] + split_speech[i+5]\n",
    "                \n",
    "                if 'committee on' in line:\n",
    "                        \n",
    "                    if ' chairman' in line_plus_2_long:\n",
    "                        chairman_name = line_plus_2_long.split(',')[0].lstrip() \n",
    "                        chairman_names.append(chairman_name)\n",
    "                        \n",
    "                    if ' chair' in line_plus_2_long:\n",
    "                        chairman_name = line_plus_2_long.split(',')[0].lstrip() \n",
    "                        chairman_names.append(chairman_name)\n",
    "                        \n",
    "                    if '(chairman)' in line_plus_2_long:\n",
    "                        line_plus_2_long = line_plus_2_long.split('(chairman)')[0]\n",
    "                        chairman_name = line_plus_2_long.split('hon.,')[-1].lstrip() \n",
    "                        chairman_names.append(chairman_name)\n",
    "                        \n",
    "                    if '(chairwoman)' in line_plus_2_long:\n",
    "                        line_plus_2_long = line_plus_2_long.split('(chairwoman)')[0]\n",
    "                        chairman_name = line_plus_2_long.split('hon.,')[-1].lstrip() \n",
    "                        chairman_names.append(chairman_name)\n",
    "                        \n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                if 'first session' in line:\n",
    "                    \n",
    "                    if ' chairman' in line_plus_2_long:\n",
    "                        chairman_name = line_plus_2_long.split(',')[0].lstrip() \n",
    "                        chairman_names.append(chairman_name)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                if 'second session' in line:\n",
    "                    \n",
    "                    if ' chairman' in line_plus_2_long:\n",
    "                        chairman_name = line_plus_2_long.split(',')[0].lstrip() \n",
    "                        chairman_names.append(chairman_name)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                elif '              house                                 senate' in line:\n",
    "                    \n",
    "                    if 'chairman' in line_plus_2_long:\n",
    "                        chairman_name = line_plus_2_long.split(', ')[0].lstrip()\n",
    "                        chairman_names.append(chairman_name)\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "                        \n",
    "            except IndexError:\n",
    "                continue\n",
    "                        \n",
    "        chairmen.append(chairman_names)\n",
    "        \n",
    "blocks_df['document_title'] = document_title\n",
    "\n",
    "blocks_df['hearing_date'] = hearing_date\n",
    "blocks_df['hearing_date'] = blocks_df['hearing_date'].str[0]\n",
    "\n",
    "blocks_df['chairman'] = chairmen\n",
    "blocks_df['chairman'] = blocks_df['chairman'].str[0]\n",
    "\n",
    "chairman_dict = {\n",
    "                 'jerry moran ' : 'jerry moran',\n",
    "                 'john thune' : 'john r. thune',\n",
    "                 'lamar alexander ' : 'lamar alexander',\n",
    "                 'tom cole' : 'thomas cole',\n",
    "                 'richard c. shelby ' : 'richard c. shelby', \n",
    "                 'lindsey graham' : 'lindsey o. graham',\n",
    "                 'lindsey graham ': 'lindsey o. graham', \n",
    "                 'roy blunt ': 'roy blunt',\n",
    "                 'susan collins, ': 'susan collins', \n",
    "                 'john hoeven ': 'john hoeven',\n",
    "                 'enzi' : 'michael b. enzi', \n",
    "                 'one hundred fourteenth congress                              ----------                                                 david vitter' : 'david vitter',\n",
    "                 '----------                                                 david vitter' : 'david vitter',\n",
    "                 'one hundred fourteenth congress                             first session                  james m. inhofe' : 'james m. inhofe',\n",
    "                 'one hundred fourteenth congress                             second session                  james m. inhofe' : 'james m. inhofe',\n",
    "                 'one hundred fourteenth congress                             first session                  barbara boxer': 'barbara boxer',\n",
    "                 'subcommittee on energy and water development                   michael k. simpson' : 'michael k. simpson',\n",
    "                 'related agencies appropriations                mario diaz-balart' : 'mario diaz-balart',\n",
    "                 'subcommittee on defense              rodney p. frelinghuysen': 'rodney p. frelinghuysen',\n",
    "                 'subcommittee on homeland security                     john r. carter': 'john r. carter',\n",
    "                 'subcommittee on defense       rodney p. frelinghuysen': 'rodney p. frelinghuysen',\n",
    "                 'subcommittee on financial services and general government                    ander crenshaw' : 'ander crenshaw',\n",
    "                 'subcommittee on energy and water development                                                                       michael k. simpson': 'michael k. simpson',\n",
    "                 'related agencies                       ken calvert' : 'ken calvert',\n",
    "                 \"william m. ``mac'' thornberry\" : 'william m. thornberry',\n",
    "                 \"one hundred fourteenth congress             william m. ``mac'' thornberry\": 'william m. thornberry',\n",
    "                 'subcommittee on interior': 'ken calvert', \n",
    "                 'hon.': 'lamar s. smith', \n",
    "                 'chairman                                  co-chairman        alcee l. hastings': 'christopher h. smith',\n",
    "                 'alcee l. hastings': 'christopher h. smith',\n",
    "                 'subcommittee on commerce': 'john abney culberson', \n",
    "                 'drug administration': 'robert b. aderholt', \n",
    "                 '[established by s. res.': 'richard burr', \n",
    "                 'washington': 'jeff flake'\n",
    "               }\n",
    "\n",
    "blocks_df= blocks_df.replace({'chairman': chairman_dict})\n",
    "\n",
    "blocks_df['speech_len'] = blocks_df['speech'].str.split().apply(len)\n",
    "\n",
    "blocks_df = blocks_df.groupby('document_id').ffill()\n",
    "\n",
    "print(f'Blocks DF shape: {blocks_df.shape}')\n",
    "blocks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df = pd.merge(blocks_df, sentences_df, left_on=['document_id', 'speech_id'], \\\n",
    "                     right_on=['document_id', 'speech_id'], how='left')\n",
    "\n",
    "speeches_df = speeches_df[~speeches_df['clean_speaker_name'].isin(['no match'])]\n",
    "speeches_df['sentence_len'] = speeches_df['sentence'].str.split().apply(len)\n",
    "speeches_df = speeches_df[speeches_df['sentence_len'] > 3]\n",
    "\n",
    "speeches_df.to_csv('speeches_df.csv', index=False)\n",
    "\n",
    "print(f'Speeches DF shape: {speeches_df.shape}')\n",
    "speeches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break speeches into paragraphs of consistent length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOO_SMALL_LENGTH = 100\n",
    "TOO_LARGE_LENGTH = 200\n",
    "\n",
    "def split_paragraph(paragraph):\n",
    "    import copy\n",
    "    list_of_paragraphs = []\n",
    "    remaining_paragraph = copy.copy(paragraph)\n",
    "    paragraph_split = remaining_paragraph.split('. ')\n",
    "    i = 0\n",
    "    while len(remaining_paragraph.split()) > TOO_LARGE_LENGTH:\n",
    "        paragraph_piece = ''\n",
    "        while len(paragraph_piece.split()) < TOO_SMALL_LENGTH:\n",
    "            paragraph_piece += paragraph_split[i]\n",
    "            i += 1\n",
    "            remaining_paragraph = '. '.join(paragraph_split[i:])\n",
    "            \n",
    "        list_of_paragraphs.append(paragraph_piece)\n",
    "    \n",
    "    if len(remaining_paragraph.split()) > TOO_SMALL_LENGTH:\n",
    "        list_of_paragraphs.append(remaining_paragraph)\n",
    "        \n",
    "    return list_of_paragraphs\n",
    "\n",
    "characters = [\"-\", \"...\", \"''\", \"``\", \"@\", \"#\",  \n",
    "              '--', '=', '_', '..', '|', \"/\",\n",
    "              '~', '—', '•', '“', '–', '>', '*']\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = text.replace(' \\n', ' ')\n",
    "    for character in characters:\n",
    "        text = text.replace(character, \" \")\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_iterations = []\n",
    "paragraphs = []\n",
    "\n",
    "for index, speech in zip(blocks_df['speech_id'], blocks_df['speech']):\n",
    "    paragraph_text = re.split('[.?!]\\n    ', speech)\n",
    "    for i, paragraph in enumerate(paragraph_text):\n",
    "        if i in skip_iterations:\n",
    "            continue\n",
    "            \n",
    "        paragraph_length = len(paragraph.split())\n",
    "        paragraph_too_small = paragraph_length < TOO_SMALL_LENGTH\n",
    "        paragraph_too_large = paragraph_length > TOO_LARGE_LENGTH\n",
    "        if paragraph_too_small:\n",
    "            try:\n",
    "                i_plus = 1\n",
    "                while len(paragraph.split()) < TOO_SMALL_LENGTH:\n",
    "                    paragraph += paragraph_text[i+i_plus]\n",
    "                    if len(paragraph.split()) > TOO_LARGE_LENGTH:\n",
    "                        raise IndexError\n",
    "                    skip_iterations.append(i+i_plus)                    \n",
    "                    i_plus += 1\n",
    "                    \n",
    "            except IndexError:\n",
    "                continue\n",
    "                \n",
    "        elif paragraph_too_large:\n",
    "            smaller_paragraphs = split_paragraph(paragraph)\n",
    "            for p in smaller_paragraphs:\n",
    "                paragraphs.append({\n",
    "                    'speech_id': index,\n",
    "                    'paragraph': re.sub(' +', ' ', p),\n",
    "                })\n",
    "                \n",
    "            continue\n",
    "        \n",
    "        if len(paragraph.split()) < TOO_SMALL_LENGTH:\n",
    "            break\n",
    "            assert False\n",
    "        paragraphs.append({\n",
    "            'speech_id': index,\n",
    "            'paragraph': re.sub(' +', ' ', paragraph),\n",
    "        })\n",
    "            \n",
    "            \n",
    "paragraphs_df = pd.DataFrame(paragraphs).reset_index().rename(columns={'index': 'paragraph_id'})\n",
    "\n",
    "paragraphs_df['paragraph_len'] = paragraphs_df['paragraph'].str.split().apply(len)\n",
    "paragraphs_df['paragraph'] = [clean_text(paragraph) for paragraph in paragraphs_df['paragraph']]\n",
    "\n",
    "paragraphs_df = paragraphs_df[paragraphs_df['paragraph_len'] <= TOO_LARGE_LENGTH]\n",
    "\n",
    "print(f'Paragraphs DF shape: {paragraphs_df.shape}')\n",
    "\n",
    "paragraphs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_paragraphs_blocks_df = pd.merge(paragraphs_df, blocks_df, on='speech_id', how='left')\n",
    "_paragraphs_temp_df = pd.merge(_paragraphs_blocks_df, speeches_df, on='document_id', how='left')\n",
    "\n",
    "congress_114_paragraphs_df = pd.merge(_paragraphs_temp_df, congressional_hearings_df.reset_index().drop(columns=['document']), left_on='document_id', right_on='index', how='left')\n",
    "\n",
    "congress_114_paragraphs_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "print(f'Full 114th Congress Paragraphs DF shape: {congress_114_paragraphs_df.shape}')\n",
    "congress_114_paragraphs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_114_paragraphs_df.document_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_paragraphs_df = congress_114_paragraphs_df[congress_114_paragraphs_df['speaker'].isin(chairmen)]\n",
    "chairman_paragraphs_df = congress_114_paragraphs_df[congress_114_paragraphs_df['chairman'] == congress_114_paragraphs_df['speaker']]\n",
    "\n",
    "def FormatParagraph(paragraph):\n",
    "    punc_filter = re.compile('([.!?]\\s*)')\n",
    "    split_with_punctuation = punc_filter.split(paragraph)\n",
    "    final = ''.join([i.capitalize() for i in split_with_punctuation])+'.'\n",
    "    return final\n",
    "\n",
    "percentage_of_speech = []\n",
    "for i, row in speaker_paragraphs_df.iterrows():\n",
    "    _percentage_of_speech = row['paragraph_len'] / speaker_paragraphs_df.groupby('speaker')['paragraph_len'].sum()[row['speaker']] * 100\n",
    "    _percentage_of_speech = round(_percentage_of_speech, 2)\n",
    "    percentage_of_speech.append(_percentage_of_speech)\n",
    "\n",
    "speaker_paragraphs_df['paragraph'] = [FormatParagraph(paragraph) for paragraph in speaker_paragraphs_df['paragraph']]\n",
    "speaker_paragraphs_df['percentage_of_speech'] = percentage_of_speech\n",
    "speaker_paragraphs_df.to_excel('speaker_paragraphs_df.xlsx', index=False)\n",
    "print(f'114th Congress Speaker Paragraphs DF shape: {speaker_paragraphs_df.shape}')\n",
    "speaker_paragraphs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {speaker_paragraphs_df.speaker.nunique()} speakers represented in the data')\n",
    "speaker_paragraphs_df.speaker.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
